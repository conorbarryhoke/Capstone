{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do this later from admin: !python -m pip install --upgrade pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#Math\n",
    "import scipy as sp\n",
    "from random import randint\n",
    "from math import exp\n",
    "import operator\n",
    "\n",
    "#Scraping\n",
    "import requests\n",
    "import json\n",
    "\n",
    "#API Packages: \n",
    "from apiclient.discovery import build\n",
    "from apiclient.errors import HttpError\n",
    "from oauth2client.tools import argparser\n",
    "\"\"\"import argparse\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\"\"\"\n",
    "\n",
    "#Modeling\n",
    "#from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "#from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.cluster import KMeans\n",
    "#from sklearn.svm import SVC\n",
    "#from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "#NLP Processing\n",
    "'''from sklearn.feature_extraction import stop_words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer'''\n",
    "\n",
    "#Time analysis\n",
    "import time\n",
    "import datetime\n",
    "from statsmodels.tsa.stattools import pacf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "\n",
    "#Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#from wordcloud import WordCloud\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_api_file = open(\"./mykey.txt\", 'r')\n",
    "my_api_str = my_api_file.read()\n",
    "my_api_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVELOPER_KEY = my_api_str\n",
    "YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
    "YOUTUBE_API_VERSION = \"v3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all views over 400M https://www.youtube.com/playlist?list=PLirAqAtl_h2r5g8xGajEwdXd3x1sZh8hC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/results?filters=video&lclk=video&search_query=a%7Cb%7Cc%7Cd%7Ce%7Cf%7Cg%7Ch%7Ci%7Cj%7Ck%7Cl%7Cm%7Cn%7Co%7Cp%7Cq%7Cr%7Cs%7Ct%7Cu%7Cv%7Cw%7Cx%7Cy%7Cz%7C1%7C1%7C2%7C3%7C4%7C5%7C6%7C7%7C8%7C9%7C0&search_sort=video_view_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YouTube Search_list filtering parameters (sort_method):\n",
    "* date – Resources are sorted in reverse chronological order based on the date they were created.\n",
    "* rating – Resources are sorted from highest to lowest rating.\n",
    "* relevance – Resources are sorted based on their relevance to the search query. This is the default value for this parameter.\n",
    "* title – Resources are sorted alphabetically by title.\n",
    "* videoCount – Channels are sorted in descending order of their number of uploaded videos.\n",
    "* viewCount – Resources are sorted from highest to lowest number of views. For live broadcasts, videos are sorted by number of concurrent viewers while the broadcasts are ongoing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function returns a list of videos according to search query 'q' as if you were typing it into the bar\n",
    "#The out put is a json list, predominantly used to get videoId's\n",
    "def youtube_search_list(q, max_results=50, sort_method='viewCount', token=None):\n",
    "  # Call the search.list method to retrieve results matching the specified query term.\n",
    "    youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION,\n",
    "    developerKey=DEVELOPER_KEY)\n",
    "\n",
    "  # Call the search.list method to retrieve results matching the specified query term.\n",
    "    search_response = youtube.search().list(\n",
    "        q=q,\n",
    "        part='id,snippet',\n",
    "        pageToken=token,\n",
    "        maxResults=max_results,\n",
    "        order=sort_method\n",
    "      ).execute()\n",
    "    \n",
    "    #output is called listresponse in api docs\n",
    "    return search_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kind': 'youtube#searchListResponse',\n",
       " 'etag': '\"XI7nbFXulYBIpL0ayR_gDh3eu1k/0Q3nkSI7oRm8zuPxi4Fv-UG_BEo\"',\n",
       " 'nextPageToken': 'CAUQAA',\n",
       " 'regionCode': 'US',\n",
       " 'pageInfo': {'totalResults': 1000000, 'resultsPerPage': 5},\n",
       " 'items': [{'kind': 'youtube#searchResult',\n",
       "   'etag': '\"XI7nbFXulYBIpL0ayR_gDh3eu1k/K8_MNnp69L0zrHbPM_-nbwUCGaY\"',\n",
       "   'id': {'kind': 'youtube#video', 'videoId': '1tAgFLmM0UU'},\n",
       "   'snippet': {'publishedAt': '2018-09-25T14:56:58.000Z',\n",
       "    'channelId': 'UC6rwiIxv0w2fbmmr66wl1rA',\n",
       "    'title': 'Luan Santana | \"A\" (Video Oficial) - Live-Móvel',\n",
       "    'description': 'Ouça #A e todo o EP #LiveMovel https://SomLivre.lnk.to/Live-Movel Composição: Bruno Caliman / #LuanSantana / Lucas Santos / Rafael Torres Tá em dúvida ...',\n",
       "    'thumbnails': {'default': {'url': 'https://i.ytimg.com/vi/1tAgFLmM0UU/default.jpg',\n",
       "      'width': 120,\n",
       "      'height': 90},\n",
       "     'medium': {'url': 'https://i.ytimg.com/vi/1tAgFLmM0UU/mqdefault.jpg',\n",
       "      'width': 320,\n",
       "      'height': 180},\n",
       "     'high': {'url': 'https://i.ytimg.com/vi/1tAgFLmM0UU/hqdefault.jpg',\n",
       "      'width': 480,\n",
       "      'height': 360}},\n",
       "    'channelTitle': 'Luan Santana',\n",
       "    'liveBroadcastContent': 'none'}},\n",
       "  {'kind': 'youtube#searchResult',\n",
       "   'etag': '\"XI7nbFXulYBIpL0ayR_gDh3eu1k/vLxCg-ozI2otcbOXvOkUKOuBXc4\"',\n",
       "   'id': {'kind': 'youtube#video', 'videoId': '-RP19fnff_c'},\n",
       "   'snippet': {'publishedAt': '2010-08-04T00:49:30.000Z',\n",
       "    'channelId': 'UCWEtnEiVwUy7mwFeshyAWLA',\n",
       "    'title': 'The Chipettes - Single Ladies [Put A Ring On It] (Official Music Video)',\n",
       "    'description': 'Watch the official video for The Chipettes \"Single Ladies [Put A Ring On It]\"! Eat your heart out Beyonce, The Chipettes are giving you a run for your money!',\n",
       "    'thumbnails': {'default': {'url': 'https://i.ytimg.com/vi/-RP19fnff_c/default.jpg',\n",
       "      'width': 120,\n",
       "      'height': 90},\n",
       "     'medium': {'url': 'https://i.ytimg.com/vi/-RP19fnff_c/mqdefault.jpg',\n",
       "      'width': 320,\n",
       "      'height': 180},\n",
       "     'high': {'url': 'https://i.ytimg.com/vi/-RP19fnff_c/hqdefault.jpg',\n",
       "      'width': 480,\n",
       "      'height': 360}},\n",
       "    'channelTitle': 'RHINO',\n",
       "    'liveBroadcastContent': 'none'}},\n",
       "  {'kind': 'youtube#searchResult',\n",
       "   'etag': '\"XI7nbFXulYBIpL0ayR_gDh3eu1k/xUf4qpflb8Yq_HlCEdTRFGJMhzs\"',\n",
       "   'id': {'kind': 'youtube#video', 'videoId': 'bo_efYhYU2A'},\n",
       "   'snippet': {'publishedAt': '2018-09-27T16:30:01.000Z',\n",
       "    'channelId': 'UC07Kxew-cMIaykMOkzqHtBQ',\n",
       "    'title': 'Lady Gaga, Bradley Cooper - Shallow (A Star Is Born)',\n",
       "    'description': 'Shallow” from A Star Is Born Soundtrack is available now: http://smarturl.it/Shallow Pre-order the soundtrack: http://smarturl.it/ASIBSoundtrack Get advance ...',\n",
       "    'thumbnails': {'default': {'url': 'https://i.ytimg.com/vi/bo_efYhYU2A/default.jpg',\n",
       "      'width': 120,\n",
       "      'height': 90},\n",
       "     'medium': {'url': 'https://i.ytimg.com/vi/bo_efYhYU2A/mqdefault.jpg',\n",
       "      'width': 320,\n",
       "      'height': 180},\n",
       "     'high': {'url': 'https://i.ytimg.com/vi/bo_efYhYU2A/hqdefault.jpg',\n",
       "      'width': 480,\n",
       "      'height': 360}},\n",
       "    'channelTitle': 'LadyGagaVEVO',\n",
       "    'liveBroadcastContent': 'none'}},\n",
       "  {'kind': 'youtube#searchResult',\n",
       "   'etag': '\"XI7nbFXulYBIpL0ayR_gDh3eu1k/1Z9LScqnT5FRNvdtOFe4cTPGMXw\"',\n",
       "   'id': {'kind': 'youtube#video', 'videoId': 't4382UVl0oc'},\n",
       "   'snippet': {'publishedAt': '2018-09-21T13:59:31.000Z',\n",
       "    'channelId': 'UCveWMJeHgcIUPMnFzd7Vxjg',\n",
       "    'title': 'Disturbed - A Reason To Fight [Official Music Video]',\n",
       "    'description': 'If you or someone you know is struggling with drug/alcohol addiction or having thoughts of suicide, please reach out to the following: AUSTRALIA Australian ...',\n",
       "    'thumbnails': {'default': {'url': 'https://i.ytimg.com/vi/t4382UVl0oc/default.jpg',\n",
       "      'width': 120,\n",
       "      'height': 90},\n",
       "     'medium': {'url': 'https://i.ytimg.com/vi/t4382UVl0oc/mqdefault.jpg',\n",
       "      'width': 320,\n",
       "      'height': 180},\n",
       "     'high': {'url': 'https://i.ytimg.com/vi/t4382UVl0oc/hqdefault.jpg',\n",
       "      'width': 480,\n",
       "      'height': 360}},\n",
       "    'channelTitle': 'Disturbed',\n",
       "    'liveBroadcastContent': 'none'}},\n",
       "  {'kind': 'youtube#searchResult',\n",
       "   'etag': '\"XI7nbFXulYBIpL0ayR_gDh3eu1k/YSIKiEal5rawBpx1lKRZEAPMQtM\"',\n",
       "   'id': {'kind': 'youtube#video', 'videoId': 'AWpsOqh8q0M'},\n",
       "   'snippet': {'publishedAt': '2009-10-03T05:02:18.000Z',\n",
       "    'channelId': 'UC9zX2xZIJ4cnwRsgBpHGvMg',\n",
       "    'title': 'Beyoncé - If I Were A Boy',\n",
       "    'description': \"Beyoncé's official video for 'If I Were A Boy'. Click to listen to Beyoncé on Spotify: http://smarturl.it/BeyonceSpotIQid=Be... As featured on I Am... Sasha Fierce.\",\n",
       "    'thumbnails': {'default': {'url': 'https://i.ytimg.com/vi/AWpsOqh8q0M/default.jpg',\n",
       "      'width': 120,\n",
       "      'height': 90},\n",
       "     'medium': {'url': 'https://i.ytimg.com/vi/AWpsOqh8q0M/mqdefault.jpg',\n",
       "      'width': 320,\n",
       "      'height': 180},\n",
       "     'high': {'url': 'https://i.ytimg.com/vi/AWpsOqh8q0M/hqdefault.jpg',\n",
       "      'width': 480,\n",
       "      'height': 360}},\n",
       "    'channelTitle': 'BeyoncéVEVO',\n",
       "    'liveBroadcastContent': 'none'}}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "youtubez = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=DEVELOPER_KEY)\n",
    "youtubez.search().list(\n",
    "    part='id,snippet',\n",
    "    q='a', \n",
    "    videoCategoryId='10',\n",
    "    type='video'\n",
    "    \n",
    "      ).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes output json list from search list and returns metadata on individual videos\n",
    "def youtube_search_video(q='spinners', max_results=50, sort_method='viewCount', token=None):\n",
    "    \n",
    "    order = \"viewCount\"\n",
    "    q=q\n",
    "    max_results = max_results\n",
    "    sort_method = sort_method\n",
    "    token = token\n",
    "    location = None\n",
    "    location_radius = None\n",
    "    \n",
    "    youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION,         \n",
    "    developerKey=DEVELOPER_KEY)\n",
    "    \n",
    "    #Return list of matching records up to max_search\n",
    "    search_result = youtube_search_list(q, max_results, sort_method, token)\n",
    "    next_tok = search_result['nextPageToken']\n",
    "    \n",
    "    videos_list = []\n",
    "    for search_result in search_result.get(\"items\", []):\n",
    "        \n",
    "        if search_result[\"id\"][\"kind\"] == 'youtube#video':\n",
    "            temp_dict_ = {}\n",
    "            #Available from initial search\n",
    "            temp_dict_['title'] = search_result['snippet']['title']  \n",
    "            temp_dict_['vidId'] = search_result['id']['videoId']  \n",
    "            \n",
    "            #Secondary call to find statistics results for individual video\n",
    "            response = youtube.videos().list(\n",
    "                part='statistics, snippet, contentDetails', \n",
    "                id=search_result['id']['videoId']\n",
    "                    ).execute()\n",
    "            #Relevant dictionaries\n",
    "            response_statistics = response['items'][0]['statistics']\n",
    "            response_snippet = response['items'][0]['snippet']\n",
    "            response_content= response['items'][0]['contentDetails']\n",
    "            \n",
    "            \n",
    "            snippet_list = ['publishedAt','channelId', 'description', \n",
    "                            'channelTitle', 'tags', 'categoryId', \n",
    "                            'liveBroadcastContent', 'defaultLanguage', ]\n",
    "            for val in snippet_list:\n",
    "                try:\n",
    "                    temp_dict_[val] = response_snippet[val]\n",
    "                except:\n",
    "                    #Not stored if not present\n",
    "                    temp_dict_[val] = 'xxNoneFoundxx'    \n",
    "            \n",
    "            stats_list = ['favoriteCount', 'viewCount', 'likeCount', \n",
    "                          'dislikeCount', 'commentCount']\n",
    "            for val in stats_list:\n",
    "                try:\n",
    "                    temp_dict_[val] = response_statistics[val]\n",
    "                except:\n",
    "                    #Not stored if not present\n",
    "                    temp_dict_[val] = 'xxNoneFoundxx'\n",
    "            \n",
    "            for val in response_content.keys():\n",
    "                try:\n",
    "                    temp_dict_[val] = response_content[val]\n",
    "                except:\n",
    "                    #Not stored if not present\n",
    "                    temp_dict_[val] = 'xxNoneFoundxx'\n",
    "                    \n",
    "            #add back to main list\n",
    "            videos_list.append(temp_dict_)\n",
    "            \n",
    "    return videos_list, next_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Hold off on this one until I figure out how to tie in google trends. \n",
    "Probably we want only comments from peak viewership plus marks at half peak on either side. \n",
    "Right now, most relevant /recent comments are all stupid meme stuff, e.g. who is watching in 2018'''\n",
    "\n",
    "#This function will grab 50 comments at a time from the video. \n",
    "def youtube_comment_list(video_id, max_results=50, sort_method='viewCount', token=None):\n",
    "  # Call the search.list method to retrieve results matching the specified query term.\n",
    "    youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION,\n",
    "    developerKey=DEVELOPER_KEY)\n",
    "\n",
    "  # Call the search.list method to retrieve results matching the specified query term.\n",
    "    search_response = youtube.commentThreads().list(\n",
    "        videoId = video_id,\n",
    "        part='snippet, replies',\n",
    "        pageToken=token,\n",
    "        order = 'relevance',\n",
    "        maxResults=max_results,\n",
    "      ).execute()\n",
    "    \n",
    "    return search_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sep 24th?'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psy = youtube_comment_list('9bZkp7q19f0')\n",
    "\n",
    "psy['items'][1]['snippet']['topLevelComment']['snippet']['textDisplay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Automation\n",
    "def youtube_search_video_looper(q,max_results=50, \n",
    "                                sort_method='viewCount', \n",
    "                                token=None, \n",
    "                                dl_path='./data/test/', dl_title='iteration'):\n",
    "    #find relevant stats, create dataframe of results, create running csvs\n",
    "    q=q,\n",
    "    max_results=max_results\n",
    "    sort_method = sort_method\n",
    "    token = token\n",
    "    \n",
    "    #Cool Start to get next token\n",
    "    videos_list, next_tok = youtube_search_video(q=q,\n",
    "                                                 max_results=max_results, \n",
    "                                                 sort_method=sort_method, \n",
    "                                                 token=token)\n",
    "    df_videos = pd.DataFrame(videos_list)\n",
    "    df_videos['request_token'] = next_tok #for assessment of run.\n",
    "\n",
    "    count=1\n",
    "    while next_tok != 'last_page':\n",
    "        try:\n",
    "\n",
    "            videos_list, next_tok = youtube_search_video(q,\n",
    "                                                         max_results=max_results, \n",
    "                                                         sort_method=sort_method, \n",
    "                                                         token=next_tok)\n",
    "            print('    found page ', count)\n",
    "            df_small_vids = pd.DataFrame(videos_list)\n",
    "            df_small_vids['request_token'] = next_tok\n",
    "            df_videos = pd.concat([df_videos, df_small_vids], sort=False)\n",
    "\n",
    "\n",
    "            #create unique text file to track progress\n",
    "            now_month = datetime.datetime.now().month\n",
    "            now_day = datetime.datetime.now().day\n",
    "            now_hour = datetime.datetime.now().hour\n",
    "            now_minute = datetime.datetime.now().minute\n",
    "            output_title = '{}{}{}_{}.{}_{}{}.csv'.format(dl_path, dl_title, count, \n",
    "                                                          now_month, now_day, now_hour, now_minute)\n",
    "            df_videos.to_csv(output_title, index=False)\n",
    "\n",
    "            count += 1\n",
    "            time.sleep(2)\n",
    "        except:\n",
    "            break\n",
    "    total_pulls = count\n",
    "    return df_videos, next_tok, total_pulls\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Stats for Data Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mv_viewCount = pd.read_csv('./data/running_video_pull.csv')  #This is my interesting class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351378"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mv_viewCount['viewCount'] = df_mv_viewCount['viewCount'].astype('int64')\n",
    "df_mv_viewCount['viewCount'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#it looks like youtube doesn't want to return too many videos like this\n",
    "#perhaps filtering by viewcount limits the effectiveness of relevance\n",
    "df_mv_viewCount.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     max irrelevant: 1300.0\n",
      "    final df size: 1625.0\n"
     ]
    }
   ],
   "source": [
    "#Given current shape, this is how many irrelevant videos I could use without \n",
    "#creating an inbalanced class\n",
    "print('     max irrelevant: {}\\n    final df size: {}'.format( df_mv_viewCount.shape[0] / .25, df_mv_viewCount.shape[0] / .25+df_mv_viewCount.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    num features: 24\n"
     ]
    }
   ],
   "source": [
    "print('    num features: {}'.format(df_videos.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a bunch of data, see what happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    found page  1\n",
      "    found page  2\n",
      "    found page  3\n",
      "    found page  4\n",
      "    found page  5\n",
      "    found page  6\n",
      "    found page  7\n",
      "    found page  8\n",
      "    found page  9\n",
      "    found page  10\n",
      "    found page  11\n",
      "    found page  12\n",
      "    found page  13\n",
      "    found page  14\n",
      "    found page  15\n",
      "    found page  16\n",
      "    found page  17\n",
      "    found page  18\n"
     ]
    }
   ],
   "source": [
    "df_videos, next_tok = youtube_search_video_looper(q='music video',max_results=50, \n",
    "                                sort_method='relevance', \n",
    "                                token=None, \n",
    "                                dl_path='./data/music_videos_relevance/', dl_title='iteration2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "good idea to set up a basic cleaning function for these - probably will do a lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_lyrics_viewCount lyric video search by viewcount\n",
    "#df_mv_relevance music video search by relevance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mv_relevance['viewCount'] = df_mv_relevance['viewCount'].map(lambda x: 0 if x=='xxNoneFoundxx' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mv_relevance['viewCount'] = df_mv_relevance['viewCount'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#duplicates\n",
    "pd.concat([df_mv_viewCount.loc[:, ['title']],  \n",
    "           df_mv_relevance.loc[:, ['title']]]).sort_values(by='title').duplicated().sum()/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Less duplicates, retrieved 300 new videos\n",
    "df_mv_relevance.shape[0] - \\\n",
    "pd.concat([df_mv_viewCount.loc[:, ['title']],  \n",
    "           df_mv_relevance.loc[:, ['title']]]).sort_values(by='title').duplicated().sum()/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
